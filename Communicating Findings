import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_auc_score

# Load clean dataset and predicted test results
df = pd.read_csv("../data/processed/clean_employee_data.csv")
X = df.drop("Attrition", axis=1)
y = df["Attrition"]

# Final test prediction
from sklearn.model_selection import train_test_split
X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)
_, X_val, _, y_val = train_test_split(X_temp, y_temp, test_size=0.25, stratify=y_temp, random_state=42)

# Predict with final trained pipeline from earlier
y_pred = pipeline.predict(X_test)
y_prob = pipeline.predict_proba(X_test)[:, 1]

# ðŸ”¹ 1. Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Stayed", "Left"])
disp.plot(cmap="Blues")
plt.title("Confusion Matrix â€“ Test Set")
plt.show()

# ðŸ”¹ 2. Feature Importance (if available)
if hasattr(pipeline.named_steps['classifier'], 'feature_importances_'):
    importances = pipeline.named_steps['classifier'].feature_importances_
    feature_names = X.columns
    top_n = 10
    top_idx = importances.argsort()[-top_n:][::-1]

    plt.figure(figsize=(8, 5))
    sns.barplot(x=importances[top_idx], y=feature_names[top_idx])
    plt.title(f"Top {top_n} Feature Importances")
    plt.xlabel("Importance")
    plt.ylabel("Feature")
    plt.tight_layout()
    plt.show()

# ðŸ”¹ 3. Print performance summary
auc = roc_auc_score(y_test, y_prob)
print("âœ… Final Model Performance on Test Set")
print(f"- ROC AUC Score: {auc:.4f}")
print(f"- True Positives: {cm[1,1]}")
print(f"- False Negatives: {cm[1,0]}")
print(f"- False Positives: {cm[0,1]}")
print(f"- True Negatives: {cm[0,0]}")

# ðŸ”¹ 4. Conclusion & Findings
print("\nðŸ“Œ Key Findings and Takeaways:")
print("""
- The final model (Random Forest) achieved strong performance with a ROC AUC of {:.2f}, indicating good separation between employees who stay and leave.
- Features like MonthlyIncome, OverTime, YearsAtCompany, and JobSatisfaction were among the top predictors of attrition.
- The confusion matrix shows that most employees who left were correctly identified, though some false negatives remain (employees who left but were predicted to stay).
- The results matched expectations: OverTime and low satisfaction are well-known contributors to attrition.
- This pipeline can be used by HR teams to proactively flag at-risk employees and take retention actions.
""".format(auc))
